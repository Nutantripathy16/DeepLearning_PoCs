{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Admissions from an Indian prespective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains several parameters which are considered important during the application for Masters Programs.\n",
    "The parameters included are :\n",
    "\n",
    "* GRE Scores ( out of 340 )\n",
    "* TOEFL Scores ( out of 120 )\n",
    "* University Rating ( out of 5 )\n",
    "* Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
    "* Undergraduate GPA ( out of 10 )\n",
    "* Research Experience ( either 0 or 1 )\n",
    "* Chance of Admit ( ranging from 0 to 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
       "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
       "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  500.00000  500.000000  500.000000         500.00000  \n",
       "mean     3.48400    8.576440    0.560000           0.72174  \n",
       "std      0.92545    0.604813    0.496884           0.14114  \n",
       "min      1.00000    6.800000    0.000000           0.34000  \n",
       "25%      3.00000    8.127500    0.000000           0.63000  \n",
       "50%      3.50000    8.560000    1.000000           0.72000  \n",
       "75%      4.00000    9.040000    1.000000           0.82000  \n",
       "max      5.00000    9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns= [\"Serial No.\"],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our target column will be chance of admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying MinMax scaling technique for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\36646\\Documents\\HavellsProjects\\DL_POCs\\dl_pocs\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> (704.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m176\u001b[0m (704.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> (704.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m176\u001b[0m (704.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1287 - val_loss: 0.0863\n",
      "Epoch 2/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0777 - val_loss: 0.0544\n",
      "Epoch 3/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0530 - val_loss: 0.0408\n",
      "Epoch 4/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - val_loss: 0.0310\n",
      "Epoch 5/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0309 - val_loss: 0.0233\n",
      "Epoch 6/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - val_loss: 0.0168\n",
      "Epoch 7/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 8/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 9/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 10/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 11/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 12/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 13/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 14/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 16/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 17/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 18/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 19/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 20/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 21/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 22/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 23/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 24/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 25/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 26/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 27/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 28/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 29/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 30/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 31/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 32/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 33/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 34/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 35/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 36/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 37/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 38/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 39/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 40/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 41/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 42/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 43/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 44/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 45/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 46/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 47/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 48/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 49/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 50/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 51/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 52/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 53/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 54/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 55/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 56/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 57/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 58/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 59/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 60/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 61/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 62/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 63/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 64/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 65/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 66/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 67/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 68/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 69/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 70/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 71/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 72/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 73/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 74/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 75/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 76/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 77/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 78/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 79/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 80/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 81/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 82/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 83/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 84/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 85/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 86/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 87/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 88/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 89/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 90/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 91/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 92/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 93/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 94/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 95/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 96/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 97/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 98/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 99/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 100/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 101/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 102/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 103/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 104/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 105/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 106/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 107/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 108/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 109/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 110/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 111/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 112/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 113/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 114/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 115/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 116/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 117/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 118/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 119/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 120/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 121/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 122/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 123/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 124/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 125/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 126/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 127/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 128/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 129/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 130/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 131/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 132/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 133/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 134/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 135/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 136/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 137/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 138/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 139/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 140/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 141/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 142/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 143/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 144/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 145/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 146/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 147/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 148/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 149/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 150/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=150,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8123454529728811"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.04128369493484497\n",
      "Mean Squared Error (MSE): 0.003623796957640694\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x229b8b86810>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
